{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.sparse\n",
    "import time\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost, textblob, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winemag-data_first150k.csv', index_col=0)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150925 entries, 0 to 150929\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   description  150925 non-null  object\n",
      " 1   winery       150925 non-null  object\n",
      " 2   country      150925 non-null  object\n",
      " 3   class        150925 non-null  int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "conditions = [\n",
    "    (data['points'] <= 84),\n",
    "    (data['points'] > 84) & (data['points'] <= 88),\n",
    "    (data['points'] > 88) & (data['points'] <= 92),\n",
    "    (data['points'] > 92) & (data['points'] <= 96),\n",
    "    (data['points'] > 96) & (data['points'] <= 100)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "class_list = [0,1,2,3,4]#['Low', 'OK', 'Good', 'Very Good', 'Excellent']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "data['class'] = np.select(conditions, class_list)\n",
    "\n",
    "data = data[['description','winery', 'country','class']] # selecting columns\n",
    "data = data.dropna() # deleting na rows\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"united\"] = data[\"country\"] + \" \" + data['winery'] + \" \" + data[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data['united'],\n",
    "                                                                    data['class'],\n",
    "                                                                    test_size=0.33,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(data['united'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "X_train =  count_vect.transform(X_train)\n",
    "X_test =  count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier,as_features,X_train,X_test, y_train,y_test):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    #dump(classifier,  type(classifier).__name__ + \"_\"+ as_features+'.joblib') \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(X_test)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes: 0.66857406738144\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(),\"count\",X_train, X_test, y_train,y_test)\n",
    "print (\"Naive Bayes:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  0.7886800787053768 time:  5.061360418796539 min\n"
     ]
    }
   ],
   "source": [
    "# RF on Count Vectors\n",
    "a = time.time()\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_jobs = -1),\"count\",X_train,X_test, y_train,y_test)\n",
    "print (\"Random Forest: \", accuracy, 'time: ', (time.time() -a)/60 ,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree::  0.7418182548287355 time:  2.834700604279836 min\n"
     ]
    }
   ],
   "source": [
    "# DT on Count Vectors\n",
    "a = time.time()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "accuracy = train_model(DecisionTreeClassifier(criterion='gini' ),\"count\",X_train,X_test, y_train,y_test)\n",
    "print (\"Decision Tree:: \", accuracy, 'time: ', (time.time() -a)/60 ,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  0.772396899971891 time:  2.0053375482559206 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksym/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# LG on Count Vectors\n",
    "a = time.time()\n",
    "accuracy = train_model(linear_model.LogisticRegression(max_iter = 500),\"count\",X_train,X_test, y_train,y_test)\n",
    "print (\"Logistic Regression: \", accuracy, 'time: ', (time.time() -a)/60 ,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksym/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP: Counting Vectors:  0.8131148857567362 time:  39.944799693425495 min\n"
     ]
    }
   ],
   "source": [
    "# MLP on Count Vectors\n",
    "#a = time.time()\n",
    "#accuracy = train_model(MLPClassifier(), \"count\",X_train,X_test, y_train,y_test)\n",
    "#print (\"MLP: Counting Vectors: \", accuracy, 'time: ', (time.time() -a)/60 ,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: Counting Vectors:  0.6978074930731237 time:  1.4257739265759786 min\n"
     ]
    }
   ],
   "source": [
    "# xgboost on Count Vectors\n",
    "a = time.time()\n",
    "accuracy = train_model(xgboost.XGBClassifier(),\"count\",X_train.tocsc(),X_test.tocsc(), y_train,y_test)\n",
    "print (\"xgboost: Counting Vectors: \", accuracy, 'time: ', (time.time() -a)/60 ,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = load('RandomForestClassifier_count.joblib')\n",
    "nb = load('MultinomialNB_count.joblib')\n",
    "lg = load('LogisticRegression_count.joblib')\n",
    "mlp = load('MLPClassifier_count.joblib')\n",
    "dt = load('DecisionTreeClassifier_count.joblib')\n",
    "xgb = load('XGBClassifier_count.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_test)\n",
    "nb_pred = nb.predict(X_test)\n",
    "lg_pred = lg.predict(X_test)\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "dt_pred = dt.predict(X_test)\n",
    "xgb_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf\n",
      "0.7886800787053768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.66      0.78      7679\n",
      "           1       0.74      0.94      0.83     22056\n",
      "           2       0.80      0.72      0.76     15917\n",
      "           3       1.00      0.46      0.63      3971\n",
      "           4       1.00      0.56      0.72       183\n",
      "\n",
      "    accuracy                           0.79     49806\n",
      "   macro avg       0.90      0.67      0.74     49806\n",
      "weighted avg       0.81      0.79      0.78     49806\n",
      "\n",
      "nb\n",
      "0.66857406738144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67      7679\n",
      "           1       0.72      0.68      0.70     22056\n",
      "           2       0.64      0.68      0.66     15917\n",
      "           3       0.54      0.56      0.55      3971\n",
      "           4       0.00      0.00      0.00       183\n",
      "\n",
      "    accuracy                           0.67     49806\n",
      "   macro avg       0.51      0.52      0.52     49806\n",
      "weighted avg       0.67      0.67      0.67     49806\n",
      "\n",
      "lg\n",
      "0.772396899971891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      7679\n",
      "           1       0.78      0.82      0.80     22056\n",
      "           2       0.75      0.75      0.75     15917\n",
      "           3       0.75      0.65      0.70      3971\n",
      "           4       0.88      0.63      0.73       183\n",
      "\n",
      "    accuracy                           0.77     49806\n",
      "   macro avg       0.79      0.72      0.75     49806\n",
      "weighted avg       0.77      0.77      0.77     49806\n",
      "\n",
      "dt\n",
      "0.7418182548287355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73      7679\n",
      "           1       0.76      0.80      0.78     22056\n",
      "           2       0.73      0.73      0.73     15917\n",
      "           3       0.67      0.56      0.61      3971\n",
      "           4       0.66      0.57      0.61       183\n",
      "\n",
      "    accuracy                           0.74     49806\n",
      "   macro avg       0.71      0.67      0.69     49806\n",
      "weighted avg       0.74      0.74      0.74     49806\n",
      "\n",
      "mlp\n",
      "0.8131148857567362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      7679\n",
      "           1       0.83      0.85      0.84     22056\n",
      "           2       0.79      0.79      0.79     15917\n",
      "           3       0.75      0.71      0.73      3971\n",
      "           4       0.89      0.64      0.74       183\n",
      "\n",
      "    accuracy                           0.81     49806\n",
      "   macro avg       0.82      0.76      0.79     49806\n",
      "weighted avg       0.81      0.81      0.81     49806\n",
      "\n",
      "xgb\n",
      "0.6978074930731237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.54      0.65      7679\n",
      "           1       0.68      0.84      0.75     22056\n",
      "           2       0.68      0.66      0.67     15917\n",
      "           3       0.82      0.37      0.51      3971\n",
      "           4       1.00      0.56      0.72       183\n",
      "\n",
      "    accuracy                           0.70     49806\n",
      "   macro avg       0.80      0.59      0.66     49806\n",
      "weighted avg       0.71      0.70      0.69     49806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( \"rf\",metrics.accuracy_score(rf_pred, y_test),classification_report(y_test,rf_pred), sep = '\\n')\n",
    "print( \"nb\",metrics.accuracy_score(nb_pred, y_test),classification_report(y_test,nb_pred),sep = '\\n')\n",
    "print( \"lg\",metrics.accuracy_score(lg_pred, y_test),classification_report(y_test,lg_pred),sep = '\\n')\n",
    "print( \"dt\",metrics.accuracy_score(dt_pred, y_test),classification_report(y_test,dt_pred),sep = '\\n')\n",
    "print( \"mlp\",metrics.accuracy_score(mlp_pred, y_test),classification_report(y_test,mlp_pred),sep = '\\n')\n",
    "print( \"xgb\",metrics.accuracy_score(xgb_pred, y_test),classification_report(y_test,xgb_pred),sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
